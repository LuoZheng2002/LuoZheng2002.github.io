# A Reassuring "Mechanical" AI Built Upon Transparent Logic

## Introduction
In recent years, the connectionist paradigm has dominated the field of AI research. Connectionism refers to approaches, such as machine learning and deep learning, that rely on large datasets from the real world and automatic training processes to develop flexible models capable of predicting outcomes in new situations. This contrasts with symbolic AI, which uses formal logic or hardcoded rules to explicitly define an AI's behavior. As large language models and deep-learning-based generative AIs flourish, it has become evident that increasing computational power and data is more effective in solving real-world problems than attempting to explicitly model the world through human labor and understanding every specific logic behind intelligence. Supported by mathematical principles like the Universal Approximation Theorem, the development of human-level AI appears to be a matter of time, as computational power and data-gathering techniques continue to advance.

However, despite their promise, current generative AIs do not always produce satisfactory outputs when given detailed specifications, leading users to question the competence of these systems. This often discourages them from fully sharing their problems, even when the AI is capable of providing a solution. Another issue arises from the perception that generative AIs lie somewhere between mechanical programs and human-like entities, creating an "uncanny valley" effect. This perception can make users hesitant to discuss sensitive or personal topics, as they may feel uncomfortable, fearing they are being observed or judged by a conscious entity.

In light of these concerns, it may be valuable to develop a more transparent, "mechanical" AI that clearly exposes its logic and decision-making processes. By assuring users that they are interacting with a machine rather than an entity with consciousness, such an AI could alleviate psychological barriers and encourage users to describe their problems in greater detail and authenticity. Additionally, by allowing users to examine the AI's "call stacks" when it provides unsatisfactory results, they could better understand where the issue lies and have the opportunity to resolve it themselves.

This project aims to develop an AI with a rule-based core algorithm that encourages users to explore its workings and contribute to its development. While intuitive tasks like image recognition are difficult to model with explicit logic, many human behaviors and reasoning processes can be explained through rules. For example, when solving a mathematical problem such as finding the integral of a function, we examine its features and apply relevant rules, a process that can be modeled explicitly. In cases where problems lack a systematic solution, such as proving a mathematical theorem, we rely on more flexible, intuitive approaches. Similarly, our AI will use a rule-based system as its core, supplemented by small-scale machine learning models for tasks requiring intuition. This combination ensures transparency while enabling the AI to handle complex, less structured problems.

The core principle behind the AI is that while connectionist approaches excel at generating ideas, rule-based algorithms are better suited for verifying solutions. To balance these strengths, the AI will follow a structured workflow. It first categorizes the problem using developer-designed templates (e.g., a math or literature problem). Based on keywords, the AI uses a small-scale machine learning model to select a relevant rule-based strategy to solve the problem. A verification process then checks the solution—whether it meets the requirements, such as ensuring a piece of code functions as specified. If the solution fails, the AI adjusts its approach using fuzzy mapping to handle conflicts and refine the strategy. The problem-solving process may iterate through several steps until the issue is resolved or no further strategies apply.

It’s unrealistic to design a single strategy that solves all problems perfectly, but we can mitigate this by implementing strategies with varying degrees of specificity. Just as the inode structure in Linux handles both small and large files efficiently, our AI will prioritize commonly encountered problems with tailored solutions. For example, the AI could focus on calculating closed-form solutions for linear regression. Users' problem descriptions will be matched to these predefined templates whenever possible, ensuring conventional, clear answers. However, for rare or unusual questions, the AI may produce less polished solutions (e.g., returning “-x+1” instead of “1-x”), reflecting the flexibility of general strategies. Specific strategies will remain backward-compatible, meaning that even specialized solutions can be broken down and understood using general rules when requested.

Unlike large language models that are designed to "grok" or generate novel strategies for new problems, this AI is built to help users navigate existing knowledge as efficiently as possible. Instead of automating the process of discovering new ideas—like proving a mathematical conjecture—our AI hardcodes connections between problems and solutions. As more points in the "problem space" are assigned strategies, the system improves its ability to handle new problems by linking them to previously mapped solutions.

Transitioning from a traditional data-driven training model to a manual, rule-based system introduces a significant workload. We plan to address this by developing a user-friendly platform for human-AI collaboration, minimizing technical barriers to enable widespread participation, just like how a game engine lowers the technical barriers and lets non-programmers engage in game development. We will also introduce "knowledge modularization" and a package management system to streamline collaborative development, allowing users to customize features and receive timely updates.

In the future, this AI’s highly transparent and debuggable structure could be applied to model the physical world with high accuracy, generating 3D simulations with realistic physics for solving complex real-life problems. It may also tackle comprehensive tasks such as game development in Unity, blending explicit knowledge with iterative problem-solving.